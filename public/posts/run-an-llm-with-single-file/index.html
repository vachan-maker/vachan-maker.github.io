<!DOCTYPE html>
<html lang="en">
<head>
    <title>
    Run an LLM with a single file | Vachan S Panicker
</title>

    <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name = "description" content = "Using an LLM on your computer is not rocket science">
<meta name = "author" content = "Vachan S Panicker">
<a rel="me" href="https://fosstodon.org/@nattukaran"></a>
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ˜Ž</text></svg>">

<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://vachan.me/images/site-feature-image.png" /><meta name="twitter:title" content="Run an LLM with a single file"/>
<meta name="twitter:description" content="Using an LLM on your computer is not rocket science"/>


<meta property="og:title" content="Run an LLM with a single file" />
<meta property="og:description" content="Using an LLM on your computer is not rocket science" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://vachan.me/posts/run-an-llm-with-single-file/" /><meta property="og:image" content="https://vachan.me/images/site-feature-image.png" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2024-06-25T11:59:00+05:30" />
<meta property="article:modified_time" content="2024-06-25T12:37:50+05:30" />



<meta name="generator" content="Hugo 0.122.0">


<link rel="canonical" href="https://vachan.me/posts/run-an-llm-with-single-file/" >


<link href="/css/style.min.ce57b461387d0e4ddbf261203554394298261bfcf7c9ae546eb9d99850498c06.css" rel="stylesheet">
<script src="https://cdn.jsdelivr.net/npm/canvas-confetti@1.9.2/dist/confetti.browser.min.js"></script>



<script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "article",
    "articleSection": "posts",
    "name": "Run an LLM with a single file",
    "headline": "Run an LLM with a single file",
    "alternativeHeadline": "",
    "description": "Using an LLM on your computer is not rocket science",
    "inLanguage": "en",
    "isFamilyFriendly": "true",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https:\/\/vachan.me\/posts\/run-an-llm-with-single-file\/"
    },
    "author" : {
        "@type": "Person",
        "name": "Vachan S Panicker"
    },
    "creator" : {
        "@type": "Person",
        "name": "Vachan S Panicker"
    },
    "accountablePerson" : {
        "@type": "Person",
        "name": "Vachan S Panicker"
    },
    "dateCreated": "2024-06-25T11:59:00.00Z",
    "datePublished": "2024-06-25T11:59:00.00Z",
    "dateModified": "2024-06-25T12:37:50.00Z",
    "image": "",
    "url" : "https:\/\/vachan.me\/posts\/run-an-llm-with-single-file\/",
    "wordCount" : "320"
}
</script>


</head>

<body>
<script data-goatcounter="https://vachan.goatcounter.com/count"
        async src="//gc.zgo.at/count.js"></script>
        <header>
   <nav>
   <h1 class = "logo" lang = "ml">à´µà´šàµ»</h1>
        <ul>
            
                <li>
                    <a href="/">Home</a>
                </li>
                
                <li>
                    <a href="/posts">Posts</a>
                </li>
                
                <li>
                    <a href="/now/">Now</a>
                </li>
                
                <li>
                    <a href="/uses">Uses</a>
                </li>
                
                <li>
                    <a href="/about">About</a>
                </li>
                
                <li>
                    <a href="/contact">Contact</a>
                </li>
                
                <li onclick="confetti({
                    spread: 180,
                    particleCount: 200
                  });">ðŸ¥³</li>
            </ul>
        </nav>
</header>

            <main>
                
    
    
        <article>
            <h1 class = "postTitle">Run an LLM with a single file</h1>
            
                <p>Using an LLM on your computer is not rocket science</p>
            
            <p class="postMeta"><strong>Posted On:</strong> Tue Jun 25, 2024 </p>
            <hr />
            <p>Last month, I came across a video by NetworkChuck on <a href="https://www.youtube.com/watch?v=Wjrdr0NU4Sk">hosting AI locally</a>. In short, he built a server specifically for running LLMs using Ollama and other tools. From his video I learned that running an LLM on your machine is actually not a complicated task.</p>
<p>But then a few weeks later, I discovered Mozilla&rsquo;s <a href="https://llamafile.ai/">llamafile</a> project which makes it even more easier to use LLMs on your computer. There is nothing to install. All you have to do is run a single file. It even comes with a web chat interface.</p>
<p>One of the big advantages of using an LLM locally is privacy. Everything runs offline and you don&rsquo;t need to worry about your data being used to train AI models.</p>
<p>To start using llamafile on Linux,</p>
<ol>
<li>
<p>Go to the project&rsquo;s repo by clicking <a href="https://github.com/Mozilla-Ocho/llamafile?tab=readme-ov-file#other-example-llamafiles">here</a> and download the model you want to run. I downloaded <code>TinyLlama-1.1B-Chat-v1.0.F16.llamafile</code> because of it&rsquo;s relatively small size. Download the model which you prefer.</p>
</li>
<li>
<p>Go to the folder where you downloaded your llamafile and open the terminal there. You will need to give permission to run the file so type the command below in the terminal.</p>
<p><code>chmod +x TinyLlama-1.1B-Chat-v1.0.F16.llamafile</code></p>
<p>(If you downloaded a different model, remember to change the file name.)</p>
</li>
<li>
<p>Run the file by entering the following command</p>
<p><code>./TinyLlama-1.1B-Chat-v1.0.F16.llamafile</code></p>
</li>
<li>
<p>Your browser should open automatically and that is all. If it doesn&rsquo;t, go to http://localhost:8080/ . That is all. See how easy that was!</p>
</li>
</ol>
<p><em>Instructions are from the llamafile <a href="https://github.com/Mozilla-Ocho/llamafile?tab=readme-ov-file#quickstart">quick start guide</a></em></p>
<p>I use a really old laptop and it was able to run the model alright. Sometimes, my desktop environment did freeze for a few moments. I actually was surprised that it was able to work on my machine.</p>
<p>Anyway, I hope you got a good idea on how simple it is to a run an LLM on your machine. Cheers!</p>
<figure><img src="llamafile.webp"
         alt="Screenshot of the web interface of running a llamafile."/><figcaption>
            <p>The TinyLlama model running on my computer</p>
        </figcaption>
</figure>

<p>This is day 30 of <a href="https://100daystooffload.com">#100DaystoOffload</a></p>

            
        </article>
        <p><a href = "mailto: vachan@tutanota.com?subject=Run%20an%20LLM%20with%20a%20single%20file&body=post-link:https%3a%2f%2fvachan.me%2fposts%2frun-an-llm-with-single-file%2f">Comment via Email</p>
        <p><a href = "/index.xml">RSS Feed</a></p>

            </main>


        <footer>
        <small>
            All work licensed under <a href = "https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> unless otherwise stated. Built with
            <a href="https://gohugo.io" class="footerLink">Hugo</a> and
            <a href="https://github.com/LordMathis/hugo-theme-nightfall" class="footerLink">Nightfall</a> theme</br>
            <img src = "/images/organic-content.svg" width = "100px" height ="100px" />
            <a href="https://512kb.club"><img src="https://512kb.club/assets/images/orange-team.svg" width = "200px" alt="a proud member of the orange team of 512KB club" /></a>
        </small>
</footer>


</body>

</html>
